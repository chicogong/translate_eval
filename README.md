# Translation Evaluation Tool

A modern, open-source platform for multilingual translation, evaluation, and TTS synthesis. All translation and evaluation are powered by AI Large Language Models (LLMs). Supports real-time translation, intelligent evaluation, batch processing, and audio synthesis with a user-friendly web interface.

## Screenshots

Below are some key UI pages to give you a quick feel of the Translation Evaluation Tool in action.

| Translation Playground | Batch Translation & Evaluation | Evaluation Dashboard |
|---|---|---|
| ![Translation Playground](docs/screenshots/trans_eval.png) | ![Batch Translation & Evaluation](docs/screenshots/batch_trans_eval.png) | ![Evaluation Statistics](docs/screenshots/eval_stat.png) |

| Evaluation Report | Mobile Simultaneous Interpretation |
|---|---|
| ![Evaluation Report](docs/screenshots/report.png) | ![Simultaneous Interpretation](docs/screenshots/simultaneous_interpretation.png) |

## Features

- ğŸŒ **Multilingual Translation (AI LLM-based)**: Translate between major languages using state-of-the-art LLMs
- ğŸ¤– **Automatic Language Detection**
- âš–ï¸ **Multi-Model Translation Comparison**: Compare translations from up to 6 different AI models side-by-side
- ğŸš€ **Batch Translation & Evaluation**: Process multiple texts concurrently with intelligent queuing and progress tracking
- ğŸ“Š **AI-powered Evaluation (LLM-based)**: Semantic accuracy, BLEU, fluency, and overall score
- ğŸµ **Text-to-Speech (TTS)**: MiniMax T2A V2 API integration
- ğŸ–¥ï¸ **Modern Web UI**: Playground, file upload, history, and statistics
- ğŸ“¦ **API-first Design**: Easy integration for developers

### Multi-Model Comparison Features

- **Side-by-Side Comparison**: Compare outputs from 2-6 AI models simultaneously
- **Parallel Processing**: All models translate concurrently for optimal performance
- **Model Selection**: Choose from configured models with user-friendly names
- **Error Handling**: Failed translations are clearly marked while successful ones are displayed
- **Easy Copy**: One-click copying of translation results
- **Responsive Design**: Optimized for various screen sizes

### Multi-Model Comparison Usage
1. Set up the environment variables in `.env` file according to [MULTI_MODEL_CONFIG.md](docs/MULTI_MODEL_CONFIG.md)
2. Run the app: `python run_app.py`
3. Open your browser at [http://127.0.0.1:8888](http://127.0.0.1:8888)
4. Click "Multi-Model Compare" to access the comparison interface

**New Features:**
- **12 Model Support**: Compare up to 12 different translation models simultaneously
- **Hunyuan Translation**: Built-in support for Tencent's Hunyuan translation service
- **Multi-Judge Evaluation**: Get scores from up to 2 different AI evaluators
- **Enhanced UI**: Beautiful, responsive interface with improved model cards and evaluation displays

### Batch Processing Features

- **Concurrent Processing**: Up to 10 simultaneous translation/evaluation tasks
- **Progress Tracking**: Real-time progress updates and completion status
- **File Upload Support**: Upload .txt files for batch processing
- **Result Export**: Download translation and evaluation results
- **History Management**: Track and review all batch operations
- **Error Handling**: Robust error recovery and retry mechanisms

### Supported Languages

- ğŸ‡ºğŸ‡¸ English (`en`)
- ğŸ‡¨ğŸ‡³ Chinese (`zh`)
- ğŸ‡¯ğŸ‡µ Japanese (`ja`)
- ğŸ‡§ğŸ‡· Portuguese (`pt`)
- ğŸ‡ªğŸ‡¸ Spanish (`es`)
- ğŸ‡«ğŸ‡· French (`fr`)
- ğŸ‡©ğŸ‡ª German (`de`)
- ğŸ‡®ğŸ‡¹ Italian (`it`)
- ğŸ‡°ğŸ‡· Korean (`ko`)
- ğŸ‡·ğŸ‡º Russian (`ru`)
- ğŸ‡³ğŸ‡± Dutch (`nl`)
- ğŸ‡¸ğŸ‡ª Swedish (`sv`)
- ğŸ‡³ğŸ‡´ Norwegian (`no`)
- ğŸ‡©ğŸ‡° Danish (`da`)
- ğŸ‡«ğŸ‡® Finnish (`fi`)
- ğŸ‡µğŸ‡± Polish (`pl`)
- ğŸ‡¨ğŸ‡¿ Czech (`cs`)
- ğŸ‡­ğŸ‡º Hungarian (`hu`)
- ğŸ‡¹ğŸ‡· Turkish (`tr`)
- ğŸ‡¦ğŸ‡· Arabic (`ar`)

240 translation directions are supported between these languages.

## Quick Start

### Requirements
- Python 3.8+
- pip

### Installation

```bash
git clone https://github.com/chicogong/translate_eval
cd translate_eval
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### Configuration
Set the following environment variables (in your shell or a `.env` file):

```bash
# Required for translation (AI LLM)
TRANSLATION_API_KEY=your_translation_api_key
TRANSLATION_API_URL=https://api.openai.com/v1/chat/completions
TRANSLATION_MODEL=gpt-4

# Required for evaluation (AI LLM)
EVALUATION_API_KEY=your_evaluation_api_key
EVALUATION_API_URL=https://api.openai.com/v1/chat/completions
EVALUATION_MODEL=gpt-4

# Optional for TTS
MINIMAX_API_KEY=your_minimax_api_key
MINIMAX_GROUP_ID=your_minimax_group_id
# Optional: custom port
FLASK_PORT=8888
```

### Run the App

```bash
# Development (default: http://127.0.0.1:8888)
python run_app.py

# Production
FLASK_ENV=production FLASK_HOST=0.0.0.0 python run_app.py
```

Open your browser at [http://127.0.0.1:8888](http://127.0.0.1:8888)

## API Overview

See [API_DOCS.md](docs/API_DOCS.md) for full details.

- `POST /api/translate` â€” Translate text (AI LLM)
- `POST /api/evaluate` â€” Evaluate translation (AI LLM)
- `POST /api/tts` â€” Text-to-speech synthesis
- `GET /api/history` â€” Translation & evaluation history
- `POST /api/batch-translate` â€” Start batch translation
- `POST /api/batch-evaluate` â€” Start batch evaluation
- `GET /api/available-runs` â€” Get available batch runs
- `GET /api/evaluation-results` â€” Get batch evaluation results

## Project Structure

```
translate_eval/
â”œâ”€â”€ backend/           # Backend Flask app & services
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ batch.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ services.py
â”‚   â”œâ”€â”€ tts_service.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ examples.py
â”‚   â”œâ”€â”€ templates/
â”‚   â””â”€â”€ static/
â”œâ”€â”€ scripts/           # Test runner
â”œâ”€â”€ tests/             # Unit tests
â”œâ”€â”€ data/              # Translation/evaluation data
â”œâ”€â”€ evaluation/        # Evaluation scripts
â”œâ”€â”€ logs/              # Log files
â”œâ”€â”€ Dockerfile         # Docker build config
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run_app.py         # App launcher
â””â”€â”€ API_DOCS.md        # API documentation
```

## Contributing

Contributions are welcome! Please open issues or pull requests to help improve this project.

## Contact

For questions, feedback, or commercial inquiries, please reach out to <chicogong@tencent.com>.

## License

MIT License. See [LICENSE](LICENSE) for details.